<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Amazon Mechanical Turk – AWS ML Specialty Ebook</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="../styles/main.css" />
    <link rel="stylesheet" href="../styles/print.css" media="print" />
  </head>
  <body class="layout">
    <header class="top-nav" role="banner">
      <div class="top-nav-title">AWS Certified Machine Learning – Specialty Ebook</div>
      <nav aria-label="Main navigation">
        <div class="top-nav-links">
          <a href="../index.html" data-page="index.html">Home</a>
          <a href="../toc.html" data-page="toc.html">Table of Contents</a>
          <a href="../practice-questions.html" data-page="practice-questions.html">Practice Questions</a>
          <a href="../glossary.html" data-page="glossary.html">Glossary</a>
          <a href="../cheat-sheet.html" data-page="cheat-sheet.html">Cheat Sheet</a>
          <a href="../search.html" data-page="search.html">Search</a>
          <a href="../about.html" data-page="about.html">About</a>
        </div>
      </nav>
    </header>
    <div class="shell">
      <aside class="sidebar" aria-label="Service navigation">
        <section class="sidebar-section">
          <h2>Data Labeling</h2>
          <ul>
            <li><a href="amazon-mechanical-turk.html">Amazon Mechanical Turk</a></li>
          </ul>
        </section>
      </aside>
      <main class="main-content" role="main">
        <p class="breadcrumbs">
          <a href="../index.html">Home</a> <span aria-hidden="true">›</span>
          <a href="../toc.html#labeling">Data Labeling</a> <span aria-hidden="true">›</span>
          Amazon Mechanical Turk
        </p>
        <h1>Amazon Mechanical Turk</h1>
        <p>
          Amazon Mechanical Turk (MTurk) is a crowdsourcing marketplace that lets you outsource micro-tasks to a
          distributed workforce. In ML contexts, it is primarily used for data labeling and human evaluation of model
          outputs when automated methods are insufficient.
        </p>

        <section>
          <h2>Key features</h2>
          <ul>
            <li>Global marketplace of workers (“Turkers”) for human intelligence tasks (HITs).</li>
            <li>Flexible task templates for classification, transcription, image annotation, and more.</li>
            <li>APIs to programmatically create, manage, and retrieve results from HITs.</li>
            <li>Qualification mechanisms to control worker access and quality.</li>
            <li>Integration patterns with SageMaker Ground Truth and custom labeling workflows.</li>
          </ul>
        </section>

        <section>
          <h2>Where it fits in ML pipelines</h2>
          <ul>
            <li>Labeling training datasets for supervised learning tasks.</li>
            <li>Collecting human judgments for subjective tasks, such as relevance or preference ranking.</li>
            <li>Human-in-the-loop evaluation and correction of model predictions.</li>
            <li>Bootstrapping labeled datasets before moving to more automated labeling services.</li>
          </ul>
        </section>

        <section>
          <h2>How it works (high level)</h2>
          <div class="diagram" role="img" aria-label="Requesters create HITs that are completed by workers, and results flow back for ML labeling.">
            <svg viewBox="0 0 540 130" xmlns="http://www.w3.org/2000/svg">
              <rect x="10" y="45" width="120" height="40" fill="#dbeafe" stroke="#1d4ed8" />
              <text x="70" y="70" text-anchor="middle" font-size="11">Requester / ML team</text>

              <rect x="160" y="30" width="160" height="70" fill="#fee2e2" stroke="#b91c1c" />
              <text x="240" y="60" text-anchor="middle" font-size="11">MTurk marketplace</text>
              <text x="240" y="78" text-anchor="middle" font-size="10">HITs &amp; workers</text>

              <rect x="350" y="20" width="170" height="35" fill="#ecfdf5" stroke="#047857" />
              <text x="435" y="42" text-anchor="middle" font-size="11">Labeled data in S3</text>

              <rect x="350" y="75" width="170" height="35" fill="#fef9c3" stroke="#a16207" />
              <text x="435" y="97" text-anchor="middle" font-size="11">Training / evaluation</text>

              <line x1="130" y1="65" x2="160" y2="65" stroke="#4b5563" marker-end="url(#arrow11)" />
              <line x1="320" y1="55" x2="350" y2="37" stroke="#4b5563" marker-end="url(#arrow11)" />
              <line x1="320" y1="75" x2="350" y2="92" stroke="#4b5563" marker-end="url(#arrow11)" />

              <defs>
                <marker id="arrow11" markerWidth="8" markerHeight="8" refX="8" refY="4" orient="auto">
                  <path d="M0,0 L8,4 L0,8 z" fill="#4b5563" />
                </marker>
              </defs>
            </svg>
          </div>
        </section>

        <section>
          <h2>CLI and SDK examples</h2>
          <p>MTurk is typically used via its own API or SDKs. The following example uses boto3.</p>
          <pre><code class="language-python">import boto3

mturk = boto3.client("mturk")

resp = mturk.list_hits(MaxResults=10)
for hit in resp.get("HITs", []):
    print(hit["HITId"], hit["Title"])</code></pre>
        </section>

        <section>
          <h2>Best practices for ML workloads</h2>
          <ul>
            <li>Design clear instructions and examples to improve label quality.</li>
            <li>Use qualifications and gold-standard questions to screen workers.</li>
            <li>Aggregate labels (for example, majority vote) to reduce noise.</li>
            <li>Consider data privacy and compliance requirements when outsourcing labeling.</li>
            <li>Use MTurk in combination with Ground Truth for managed and semi-automated labeling workflows.</li>
          </ul>
        </section>

        <section class="exam-tips callout">
          <h2>Exam tips</h2>
          <ul>
            <li>MTurk appears when you need large-scale human labeling without building your own workforce.</li>
            <li>Ground Truth offers more ML-specific features; MTurk is a general-purpose marketplace.</li>
            <li>Look for keywords like “crowdsourcing” or “global workforce” in exam questions.</li>
          </ul>
        </section>

        <section>
          <h2>Further reading</h2>
          <ul>
            <li><a href="https://docs.aws.amazon.com/mturk/latest/userguide/welcome.html">Amazon Mechanical Turk User Guide – Welcome</a></li>
            <li><a href="https://www.mturk.com/">Amazon Mechanical Turk website</a></li>
            <li><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html">SageMaker Ground Truth documentation</a></li>
          </ul>
        </section>

        <p class="source-line">
          Source: <a href="https://docs.aws.amazon.com/mturk/latest/userguide/welcome.html">Amazon Mechanical Turk User Guide</a>.
          Last reviewed: 2025-11-16 (offline, approximate).
        </p>
      </main>
    </div>
    <footer class="site-footer" role="contentinfo">
      Mechanical Turk is a flexible but less ML-specialized option for obtaining labeled data and human judgments at scale.
    </footer>
    <script src="../scripts/prism.js"></script>
    <script src="../scripts/main.js"></script>
  </body>
</html>

